# Ollama Parser Configuration
# Model Configuration

# OCR Model Configuration
# Default: deepseek-ocr:latest
# You can change to any OCR model available in Ollama
OCR_MODEL=deepseek-ocr:latest

# VLM Model Configuration
# Default: gemma3:27b
VLM_MODEL=qwen3-vl:4b

# Ollama Server Configuration
OLLAMA_HOST=http://localhost:11434

# OpenAI API Configuration (for openai-vlm / openai-ocr providers)
# Required if using real OpenAI API.
# If using vLLM, you can leave API Key as 'EMPTY' and set BASE_URL.
OPENAI_API_KEY=sk-your-openai-api-key

# Optional: Set this to point to vLLM or other OpenAI-compatible endpoints
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_BASE_URL=http://localhost:8000/v1
